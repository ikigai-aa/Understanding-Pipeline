{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undestanding Pipelines with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading neccessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Using built-in Iris Flower dataset for understanding the concept of classification problem\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 3. , 1.4, 0.2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Iris Flower dataset into the notebook\n",
    "df_iris= load_iris()\n",
    "df_iris.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(df_iris.data, df_iris.target, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creting Pipelines considering 3 different Machine Learning Algorithm\n",
    "# 1. Data Preprocssing using StandardScaler\n",
    "# 2. Reducing Dimensions using PCA\n",
    "# 3. Apply Classifier\n",
    "\n",
    "pipeline_lr= Pipeline([('scaler_1',StandardScaler()),\n",
    "                       ('pca_1', PCA(n_components=2)),\n",
    "                       ('clf_lr', LogisticRegression(random_state=0))])\n",
    "\n",
    "pipeline_dt= Pipeline([('scaler2', StandardScaler()),\n",
    "                       ('pca_2', PCA(n_components=2)),\n",
    "                       ('clf_dt',DecisionTreeClassifier())])\n",
    "\n",
    "pipeline_rf= Pipeline([('scaler_3', StandardScaler()),\n",
    "                       ('pca_3', PCA(n_components=2)),\n",
    "                       ('clf_rf', RandomForestClassifier())])\n",
    "\n",
    "pipelines= [pipeline_lr, pipeline_dt, pipeline_rf]\n",
    "\n",
    "\n",
    "# Initializing the best accuracy, classifier and pipelines\n",
    "best_accuracy= 0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\"\n",
    "\n",
    "pipeline_dict= {0: 'Logistic regression',\n",
    "                1: 'Decision Tree',\n",
    "                2: 'Random Forest'}\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy by Logistic regression: 0.8666666666666667\n",
      "Test Accuracy by Decision Tree: 0.9111111111111111\n",
      "Test Accuracy by Random Forest: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(pipelines):\n",
    "    print(\"Test Accuracy by {}: {}\".format(pipeline_dict[i], model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        RandomForestClassifier(bootstrap=True,\n",
       "                                                               ccp_alpha=0.0,\n",
       "                                                               class_weight=None,\n",
       "                                                               criterion='gini',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features='auto',\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               max_samples=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_lea...\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         n_estimators=100,\n",
       "                                                         n_jobs=None,\n",
       "                                                         oob_score=False,\n",
       "                                                         random_state=None,\n",
       "                                                         verbose=0,\n",
       "                                                         warm_start=False)],\n",
       "                          'clf__max_depth': [5, 8, 15, 25, 30, None],\n",
       "                          'clf__max_leaf_nodes': [2, 5, 10],\n",
       "                          'clf__min_samples_leaf': [1, 2, 5, 10, 15, 100],\n",
       "                          'clf__n_estimators': [10, 100, 1000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Hyperparameter Tuning using GridSearchCV\n",
    "\n",
    "pipe= Pipeline([('clf', RandomForestClassifier())])\n",
    "\n",
    "# Creating parameter grids\n",
    "\n",
    "param_grids= [\n",
    "    {\"clf\": [LogisticRegression()],\n",
    "     \"clf__penalty\": ['l2', 'l1'],\n",
    "     \"clf__C\": np.logspace(0,4,10)\n",
    "    },\n",
    "    \n",
    "    {\"clf\": [LogisticRegression()],\n",
    "     \"clf__penalty\": ['l2'],\n",
    "     \"clf__C\": np.logspace(0,4,10),\n",
    "     \"clf__solver\":['newton-cg', 'saga', 'sag', 'liblinear']\n",
    "    },\n",
    "    \n",
    "    {\"clf\": [RandomForestClassifier()],\n",
    "     \"clf__n_estimators\": [10,100,1000],\n",
    "     \"clf__max_depth\": [5,8,15,25,30,None],\n",
    "     \"clf__min_samples_leaf\": [1,2,5,10,15,100],\n",
    "     \"clf__max_leaf_nodes\": [2,5,10]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search= GridSearchCV(pipe, param_grids, cv=5, verbose=0, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Prediction on test set\n",
    "y_pred= grid_search.predict(X_test)\n",
    "\n",
    "# Checking the accuracy score of the model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 16,  2],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pred_labels\n",
       "0            2\n",
       "1            1\n",
       "2            0\n",
       "3            2\n",
       "4            0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final= pd.DataFrame(data= y_pred, columns=['Pred_labels'])\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
